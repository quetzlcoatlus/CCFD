{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dfc23bc-1905-4da7-bc79-1caf81495135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import SGDClassifier # SGD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd612aaf-d143-4388-91e6-034a463d400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading into data frame from file\n",
    "data_frame = pd.read_csv('./creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bcc6ddf-a4b1-4ff3-a3cc-cbd2f0355903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models from files if desired\n",
    "from pickle import load\n",
    "load_models = True\n",
    "save_models = False\n",
    "\n",
    "if load_models:\n",
    "    with open(\"SGDClassifier_model.pkl\", \"rb\") as file:\n",
    "        clf = load(file)\n",
    "    with open(\"SGDClassifier_model_resampled.pkl\", \"rb\") as file:\n",
    "        clf_resampled = load(file)\n",
    "else:\n",
    "    clf, clf_resampled = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dca4ee6-4f2c-42ee-a20d-bf9dec651296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to fit and targets\n",
    "feature_set = [\"Time\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\", \"V10\", \"V11\", \"V12\", \"V13\", \"V14\", \"V15\", \"V16\", \"V17\", \"V18\", \"V19\", \"V20\", \"V21\", \"V22\", \"V23\", \"V24\", \"V25\", \"V26\", \"V27\", \"V28\", \"Amount\"]\n",
    "target_set = [\"Class\"]\n",
    "\n",
    "X = data_frame[feature_set]\n",
    "y = data_frame[target_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f26ada4-edf9-4d34-92a7-234b5cf607b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits data into 80-20 train-test\n",
    "# Prevents data leakage (where training and test sets influence each other in scaling)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33953908-50fe-4cb4-a07b-18abdf03891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Standard scaling\n",
    "X_train_standard_scaled = standard_scaler.fit_transform(X_train)\n",
    "X_test_standard_scaled = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d519c9ee-bf7f-4b93-b549-e4ad8e9ba6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing data set with resampling\n",
    "\n",
    "# Separate majority and minority classes in training set\n",
    "X_train_majority = X_train[y_train[\"Class\"] == 0]\n",
    "y_train_majority = y_train[y_train[\"Class\"] == 0]\n",
    "X_train_minority = X_train[y_train[\"Class\"] == 1]\n",
    "y_train_minority = y_train[y_train[\"Class\"] == 1]\n",
    "\n",
    "# Oversample minority class\n",
    "X_minority_upsampled, y_minority_upsampled = resample(\n",
    "    X_train_minority, y_train_minority,\n",
    "    replace=True,                      # sample with replacement\n",
    "    n_samples=len(y_train_majority),  # match majority class\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Combine majority and upsampled minority\n",
    "X_train_resampled = pd.concat((X_train_majority, X_minority_upsampled))\n",
    "y_train_resampled = pd.concat((y_train_majority, y_minority_upsampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3412052f-f648-4cd5-a170-a23de0233266",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      8\u001b[39m X_minority_upsampled_standard_scaled, y_minority_upsampled = resample(\n\u001b[32m      9\u001b[39m     X_train_minority_standard_scaled, y_train_minority,\n\u001b[32m     10\u001b[39m     replace=\u001b[38;5;28;01mTrue\u001b[39;00m,                      \u001b[38;5;66;03m# sample with replacement\u001b[39;00m\n\u001b[32m     11\u001b[39m     n_samples=\u001b[38;5;28mlen\u001b[39m(y_train_majority),  \u001b[38;5;66;03m# match majority class\u001b[39;00m\n\u001b[32m     12\u001b[39m     random_state=\u001b[32m1\u001b[39m\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Combine majority and upsampled minority\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m X_train_resampled_standard_scaled = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_majority_standard_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_minority_upsampled_standard_scaled\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m y_train_resampled = pd.concat((y_train_majority, y_minority_upsampled))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/ml-project-2025/lib/python3.12/site-packages/pandas/core/reshape/concat.py:382\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m op = \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/ml-project-2025/lib/python3.12/site-packages/pandas/core/reshape/concat.py:448\u001b[39m, in \u001b[36m_Concatenator.__init__\u001b[39m\u001b[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[39m\n\u001b[32m    445\u001b[39m objs, keys = \u001b[38;5;28mself\u001b[39m._clean_keys_and_objs(objs, keys)\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m448\u001b[39m ndims = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_ndims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    449\u001b[39m sample, objs = \u001b[38;5;28mself\u001b[39m._get_sample_object(objs, ndims, keys, names, levels)\n\u001b[32m    451\u001b[39m \u001b[38;5;66;03m# Standardize axis parameter to int\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/ml-project-2025/lib/python3.12/site-packages/pandas/core/reshape/concat.py:489\u001b[39m, in \u001b[36m_Concatenator._get_ndims\u001b[39m\u001b[34m(self, objs)\u001b[39m\n\u001b[32m    484\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[32m    485\u001b[39m         msg = (\n\u001b[32m    486\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcannot concatenate object of type \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    487\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33monly Series and DataFrame objs are valid\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    488\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m    491\u001b[39m     ndims.add(obj.ndim)\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ndims\n",
      "\u001b[31mTypeError\u001b[39m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "# Balancing data set with resampling ON SCALED DATA\n",
    "\n",
    "# Separate majority and minority classes in training set\n",
    "X_train_majority_standard_scaled = X_train_standard_scaled[y_train[\"Class\"] == 0]\n",
    "X_train_minority_standard_scaled = X_train_standard_scaled[y_train[\"Class\"] == 1]\n",
    "\n",
    "# Oversample minority class\n",
    "X_minority_upsampled_standard_scaled, y_minority_upsampled = resample(\n",
    "    X_train_minority_standard_scaled, y_train_minority,\n",
    "    replace=True,                      # sample with replacement\n",
    "    n_samples=len(y_train_majority),  # match majority class\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Combine majority and upsampled minority\n",
    "X_train_resampled_standard_scaled = pd.concat((X_train_majority_standard_scaled, X_minority_upsampled_standard_scaled))\n",
    "y_train_resampled = pd.concat((y_train_majority, y_minority_upsampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d20642f-224e-453c-af00-b3ac4ab60461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model(s)\n",
    "if clf == None:\n",
    "    clf = SGDClassifier(random_state=1) # Apparently prefers standard scaling\n",
    "if clf_resampled == None:\n",
    "    clf_resampled = SGDClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94f0e29-4678-4a98-b77e-235062764c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect predictions from non-resample trained model\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Collect predictions from resample trained model\n",
    "clf_resampled.fit(X_train_resampled, y_train_resampled)\n",
    "y_resampled_pred = clf_resampled.predict(X_test)\n",
    "\n",
    "# Collect predictions from non-resample trained model (standard scaled)\n",
    "clf.fit(X_train_standard_scaled, y_train)\n",
    "y_standard_scale_pred = clf.predict(X_test_standard_scaled)\n",
    "\n",
    "# Collect predictions from resample trained model (standard scaled)\n",
    "clf_resampled.fit(X_train_resampled_standard_scaled, y_train_resampled)\n",
    "y_standard_scale_resampled_pred = clf_resampled.predict(X_test_standard_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
